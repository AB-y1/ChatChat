{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "#     langchain==0.0.292 \\\n",
    "#     openai==0.28.0 \\\n",
    "#     datasets==2.10.1 \\\n",
    "#     pinecone-client==2.2.4 \\\n",
    "#     tiktoken==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#chatbot\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# Open and read the content of the file, removing any leading/trailing whitespaces\n",
    "with open(r\"C:\\Users\\HP\\Desktop\\week_six_Api_key.txt\", 'r') as file:\n",
    "    API_key = file.read().strip()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or API_key\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=API_key,\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand this week 10 Academy challenge\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Of course! The Week 10 Academy challenge is a task given to participants of the Academy program. The specific details of the challenge can vary depending on the program or course you are taking, but generally, it is designed to test your skills and knowledge in a particular area.\\n\\nThe challenge could be a coding or programming task, a problem-solving exercise, a data analysis project, or any other relevant activity. It is meant to challenge you and allow you to apply what you have learned throughout the program.\\n\\nTo better understand the specific details and requirements of your Week 10 challenge, I would recommend referring to the materials and instructions provided by your program facilitators or mentors. They will have the most accurate and up-to-date information regarding the challenge.\\n\\nIf you have any specific questions or need assistance with any aspect of the challenge, feel free to ask, and I'll do my best to help you out!\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! The Week 10 Academy challenge is a task given to participants of the Academy program. The specific details of the challenge can vary depending on the program or course you are taking, but generally, it is designed to test your skills and knowledge in a particular area.\n",
      "\n",
      "The challenge could be a coding or programming task, a problem-solving exercise, a data analysis project, or any other relevant activity. It is meant to challenge you and allow you to apply what you have learned throughout the program.\n",
      "\n",
      "To better understand the specific details and requirements of your Week 10 challenge, I would recommend referring to the materials and instructions provided by your program facilitators or mentors. They will have the most accurate and up-to-date information regarding the challenge.\n",
      "\n",
      "If you have any specific questions or need assistance with any aspect of the challenge, feel free to ask, and I'll do my best to help you out!\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but as an AI language model, I don't have access to specific information about your Week 10 Academy challenge. The first task of the challenge will depend on the program or course you are taking, and it may vary for each participant.\n",
      "\n",
      "I would recommend referring to the materials and instructions provided by your program facilitators or mentors. They will be able to provide you with the specific details and requirements of the first task.\n",
      "\n",
      "If you have any other questions or need assistance with a different topic, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"What is first task of it\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_six = [\"Learning Outcomes of week six challeng\",\n",
    "            \"Skills Development\",\n",
    "            \"Prompt Engineering Proficiency: Gain expertise in crafting effective prompts that guide LLMs to desired outputs, understanding nuances and variations in language that impact model responses.\",\n",
    "            \"Critical Analysis: Develop the ability to critically analyze and evaluate the effectiveness of different prompts based on their performance in varied scenarios.\",\n",
    "            \"Technical Aptitude with LLMs: Enhance technical skills in using advanced language models like GPT-4 and GPT-3.5-Turbo, understanding their functionalities and capabilities.\",\n",
    "            \"Problem-Solving and Creativity: Cultivate creative problem-solving skills by generating innovative prompts and test cases, addressing complex and varied objectives.\",\n",
    "            \"Data Interpretation: Learn to interpret and analyze data from test cases and prompt evaluations, deriving meaningful insights from performance metrics.\",\n",
    "            \"Knowledge Acquisition\",\n",
    "            \"Understanding of Language Models: Acquire a deeper understanding of how LLMs function, including their strengths, limitations, and the principles behind their responses.\",\n",
    "            \"Insights into Automated Evaluation Data Generation: Gain knowledge about the methodology and importance of creating test cases for evaluating prompt effectiveness.\",\n",
    "            \"ELO Rating System and its Applications: Learn about the ELO rating system used for ranking prompts, understanding its mechanics and relevance in performance evaluation.\",\n",
    "            \"Prompt Optimization Strategies: Understand various strategies for refining and optimizing prompts to achieve better alignment with specific goals and desired outcomes.\",\n",
    "            \"Industry Best Practices: Familiarize with the best practices in prompt engineering within different industries, learning about real-world applications and challenges.\"\n",
    "\n",
    "            \n",
    "]\n",
    "\n",
    "source_knowledge = \"\\n\".join(week_six)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you tell me about skills that week six develop?\"\n",
    "\n",
    "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we feed this into our chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skills developed in week six include:\n",
      "\n",
      "1. Prompt Engineering Proficiency: This skill focuses on crafting effective prompts that guide language models to produce desired outputs. It involves understanding the nuances and variations in language that can impact model responses.\n",
      "\n",
      "2. Critical Analysis: This skill involves developing the ability to critically analyze and evaluate the effectiveness of different prompts based on their performance in varied scenarios. It helps in assessing the quality and impact of prompts on the language models' outputs.\n",
      "\n",
      "3. Technical Aptitude with LLMs: This skill aims to enhance technical skills in using advanced language models like GPT-4 and GPT-3.5-Turbo. It involves understanding the functionalities and capabilities of these models to leverage their potential effectively.\n",
      "\n",
      "4. Problem-Solving and Creativity: This skill focuses on cultivating creative problem-solving skills by generating innovative prompts and test cases. It helps in addressing complex and varied objectives while utilizing language models effectively.\n",
      "\n",
      "5. Data Interpretation: This skill involves learning to interpret and analyze data from test cases and prompt evaluations. It helps in deriving meaningful insights from performance metrics to evaluate and improve prompt effectiveness.\n",
      "\n",
      "These skills are essential for prompt engineering and leveraging language models effectively. They contribute to a deeper understanding of language models, prompt optimization strategies, industry best practices, and the ELO rating system used for ranking prompts.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
