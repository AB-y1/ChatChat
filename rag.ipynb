{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    langchain==0.0.292 \\\n",
    "    openai==0.28.0 \\\n",
    "    datasets==2.10.1 \\\n",
    "    pinecone-client==2.2.4 \\\n",
    "    tiktoken==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#chatbot\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"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\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=\"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\",\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand this week 10 Academy challenge\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Of course! The Week 10 Academy challenge is a project or assignment that participants in the Week 10 of the Academy program are given to complete. The specific details of the challenge may vary depending on the program or course you are taking, but generally, it is designed to test the skills and knowledge you have acquired throughout the program.\\n\\nThe challenge often involves working on a real-world problem or scenario and applying the concepts, techniques, and tools you have learned. It may require you to use programming languages, data analysis methods, machine learning algorithms, or other relevant skills to solve the problem.\\n\\nTo understand the specific requirements and scope of the Week 10 challenge, you should refer to the instructions provided by your instructors or program facilitators. They will usually provide you with the necessary guidelines, datasets (if applicable), and any additional resources or support you may need to successfully complete the challenge.\\n\\nIf you have any specific questions or need further clarification about the challenge, feel free to ask, and I'll be happy to assist you!\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! The Week 10 Academy challenge is a project or assignment that participants in the Week 10 of the Academy program are given to complete. The specific details of the challenge may vary depending on the program or course you are taking, but generally, it is designed to test the skills and knowledge you have acquired throughout the program.\n",
      "\n",
      "The challenge often involves working on a real-world problem or scenario and applying the concepts, techniques, and tools you have learned. It may require you to use programming languages, data analysis methods, machine learning algorithms, or other relevant skills to solve the problem.\n",
      "\n",
      "To understand the specific requirements and scope of the Week 10 challenge, you should refer to the instructions provided by your instructors or program facilitators. They will usually provide you with the necessary guidelines, datasets (if applicable), and any additional resources or support you may need to successfully complete the challenge.\n",
      "\n",
      "If you have any specific questions or need further clarification about the challenge, feel free to ask, and I'll be happy to assist you!\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but as an AI language model, I do not have access to specific information about the Week 10 Academy challenge or its tasks. The challenge can vary depending on the program or course you are taking, and the specific tasks are determined by your instructors or program facilitators.\n",
      "\n",
      "To find out the first task of the Week 10 challenge, I recommend referring to the instructions or guidelines provided by your instructors or reaching out to them for clarification. They will be able to provide you with the necessary details and guidance to successfully complete the challenge.\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"What is first task of it\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Learning Outcomes of week six challeng \n",
    "Skills Development\n",
    "Prompt Engineering Proficiency: Gain expertise in crafting effective prompts that guide LLMs to desired outputs, understanding nuances and variations in language that impact model responses.\n",
    "Critical Analysis: Develop the ability to critically analyze and evaluate the effectiveness of different prompts based on their performance in varied scenarios.\n",
    "Technical Aptitude with LLMs: Enhance technical skills in using advanced language models like GPT-4 and GPT-3.5-Turbo, understanding their functionalities and capabilities.\n",
    "Problem-Solving and Creativity: Cultivate creative problem-solving skills by generating innovative prompts and test cases, addressing complex and varied objectives.\n",
    "Data Interpretation: Learn to interpret and analyze data from test cases and prompt evaluations, deriving meaningful insights from performance metrics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llmchain_information' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m week_six \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning Outcomes of week six challeng\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      2\u001b[0m ]\n\u001b[1;32m----> 4\u001b[0m source_knowledge \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mllmchain_information\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llmchain_information' is not defined"
     ]
    }
   ],
   "source": [
    "week_six = [\"Learning Outcomes of week six challeng\",\n",
    "            \"Skills Development\",\n",
    "            \"Prompt Engineering Proficiency: Gain expertise in crafting effective prompts that guide LLMs to desired outputs, understanding nuances and variations in language that impact model responses.\",\n",
    "            \"Critical Analysis: Develop the ability to critically analyze and evaluate the effectiveness of different prompts based on their performance in varied scenarios.\",\n",
    "            \"Technical Aptitude with LLMs: Enhance technical skills in using advanced language models like GPT-4 and GPT-3.5-Turbo, understanding their functionalities and capabilities.\",\n",
    "            \"Problem-Solving and Creativity: Cultivate creative problem-solving skills by generating innovative prompts and test cases, addressing complex and varied objectives.\",\n",
    "            \"Data Interpretation: Learn to interpret and analyze data from test cases and prompt evaluations, deriving meaningful insights from performance metrics.\",\n",
    "            \"Knowledge Acquisition\",\n",
    "            \"Understanding of Language Models: Acquire a deeper understanding of how LLMs function, including their strengths, limitations, and the principles behind their responses.\",\n",
    "            \"Insights into Automated Evaluation Data Generation: Gain knowledge about the methodology and importance of creating test cases for evaluating prompt effectiveness.\",\n",
    "            \"ELO Rating System and its Applications: Learn about the ELO rating system used for ranking prompts, understanding its mechanics and relevance in performance evaluation.\",\n",
    "            \"Prompt Optimization Strategies: Understand various strategies for refining and optimizing prompts to achieve better alignment with specific goals and desired outcomes.\",\n",
    "            \"Industry Best Practices: Familiarize with the best practices in prompt engineering within different industries, learning about real-world applications and challenges.\"\n",
    "\n",
    "            \n",
    "]\n",
    "\n",
    "source_knowledge = \"\\n\".join(week_six)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
